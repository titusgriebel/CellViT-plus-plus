{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CoNSeP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from https://warwick.ac.uk/fac/cross_fac/tia/data/\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to dataset\n",
    "\n",
    "orig_dataset_path = Path(\"path/to/original/Consep\")\n",
    "cellvit_dataset_path = Path(\"path/to/transformed/Consep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Rescale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Test images\n",
    "test_input_path = orig_dataset_path / \"Test\" / \"Images\"\n",
    "test_output_path = cellvit_dataset_path / \"Test\" / \"images\"\n",
    "test_output_path.mkdir(parents=True, exist_ok=True)\n",
    "test_image_files = list(test_input_path.glob(\"*.png\"))\n",
    "for img_file in test_image_files:\n",
    "    loaded_image = Image.open(img_file)\n",
    "    resized = loaded_image.resize((1024, 1024), resample=Image.Resampling.LANCZOS)\n",
    "    new_img_path = test_output_path / f\"{img_file.stem}.png\"\n",
    "    resized.save(new_img_path)\n",
    "    \n",
    "# 2. Train images\n",
    "\n",
    "train_input_path = orig_dataset_path / \"Train\" / \"Images\"\n",
    "train_output_path = cellvit_dataset_path / \"Train\" / \"images\"\n",
    "train_output_path.mkdir(parents=True, exist_ok=True)\n",
    "train_image_files = list(train_input_path.glob(\"*.png\"))\n",
    "for img_file in train_image_files:\n",
    "    loaded_image = Image.open(img_file)\n",
    "    resized = loaded_image.resize((1024, 1024), resample=Image.Resampling.LANCZOS)\n",
    "    new_img_path = train_output_path / f\"{img_file.stem}.png\"\n",
    "    resized.save(new_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Convert labels to numpy and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Test images\n",
    "test_input_path = orig_dataset_path / \"Test\" / \"Labels\"\n",
    "test_mask_files = list(test_input_path.glob(\"*.mat\"))\n",
    "\n",
    "test_output_path = cellvit_dataset_path / \"Test\" / \"labels-1000-1000\"\n",
    "test_output_path_resized = cellvit_dataset_path / \"Test\" / \"labels\"\n",
    "test_output_path.mkdir(parents=True, exist_ok=True)\n",
    "test_output_path_resized.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for mask_file in test_mask_files:\n",
    "    loaded_mask= loadmat(mask_file)\n",
    "    inst_map = loaded_mask[\"inst_map\"]\n",
    "    inst_map_resized = np.array(Image.fromarray(inst_map).resize(\n",
    "        (1024, 1024), resample=Image.Resampling.NEAREST\n",
    "    )).astype(np.float64)\n",
    "    type_map = loaded_mask[\"type_map\"]\n",
    "    type_map_resized = np.array(Image.fromarray(type_map).resize(\n",
    "        (1024, 1024), resample=Image.Resampling.NEAREST\n",
    "    )).astype(np.float64)\n",
    "    output_mask = {\n",
    "        \"inst_map\": inst_map,\n",
    "        \"type_map\": type_map,\n",
    "    }\n",
    "    output_mask_resized = {\n",
    "        \"inst_map\": inst_map_resized,\n",
    "        \"type_map\": type_map_resized,\n",
    "    }\n",
    "    new_mask_path = test_output_path / f\"{mask_file.stem}.npy\"   \n",
    "    np.save(new_mask_path, output_mask)\n",
    "    new_mask_path_resized = test_output_path_resized / f\"{mask_file.stem}.npy\"\n",
    "    np.save(new_mask_path_resized, output_mask_resized)\n",
    "    \n",
    "# 2. Train images\n",
    "train_input_path = orig_dataset_path / \"Train\" / \"Labels\"\n",
    "train_mask_files = list(test_input_path.glob(\"*.mat\"))\n",
    "\n",
    "train_output_path = cellvit_dataset_path / \"Train\" / \"labels-1000-1000\"\n",
    "train_output_path_resized = cellvit_dataset_path / \"Train\" / \"labels\"\n",
    "train_output_path.mkdir(parents=True, exist_ok=True)\n",
    "train_output_path_resized.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for mask_file in train_mask_files:\n",
    "    loaded_mask= loadmat(mask_file)\n",
    "    inst_map = loaded_mask[\"inst_map\"]\n",
    "    inst_map_resized = np.array(Image.fromarray(inst_map).resize(\n",
    "        (1024, 1024), resample=Image.Resampling.NEAREST\n",
    "    )).astype(np.float64)\n",
    "    type_map = loaded_mask[\"type_map\"]\n",
    "    type_map_resized = np.array(Image.fromarray(type_map).resize(\n",
    "        (1024, 1024), resample=Image.Resampling.NEAREST\n",
    "    )).astype(np.float64)\n",
    "    output_mask = {\n",
    "        \"inst_map\": inst_map,\n",
    "        \"type_map\": type_map,\n",
    "    }\n",
    "    output_mask_resized = {\n",
    "        \"inst_map\": inst_map_resized,\n",
    "        \"type_map\": type_map_resized,\n",
    "    }\n",
    "    new_mask_path = train_output_path / f\"{mask_file.stem}.npy\"   \n",
    "    np.save(new_mask_path, output_mask)\n",
    "    new_mask_path_resized = train_output_path_resized / f\"{mask_file.stem}.npy\"\n",
    "    np.save(new_mask_path_resized, output_mask_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplary configs can be found in the log folder:\n",
    "# ./logs/Classifiers/CoNSeP\n",
    "\n",
    "# python3 ./cellvit/train_cell_classifier_head.py --config /path/to/your/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate with consep-evaluation metrics\n",
    "# python3 ./cellvit/training/evaluate/inference_cellvit_experiment_consep.py --help\n",
    "\n",
    "\n",
    "\n",
    "# usage: inference_cellvit_experiment_consep.py [-h] [--logdir LOGDIR] [--dataset_path DATASET_PATH] [--cellvit_path CELLVIT_PATH] [--normalize_stains] [--gpu GPU]\n",
    "\n",
    "# Perform CellViT-Classifier inference for CoNSeP\n",
    "\n",
    "# options:\n",
    "#   -h, --help            show this help message and exit\n",
    "#   --logdir LOGDIR       Path to the log directory with the trained head. (default: None)\n",
    "#   --dataset_path DATASET_PATH\n",
    "#                         Path to the CoNSeP dataset (default: None)\n",
    "#   --cellvit_path CELLVIT_PATH\n",
    "#                         Path to the Cellvit model (default: None)\n",
    "#   --normalize_stains    If stains should be normalized for inference (default: False)\n",
    "#   --gpu GPU             Number of CUDA GPU to use (default: 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellvit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
